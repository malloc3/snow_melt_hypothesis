{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd05be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is to take a CSV of specific format (illustrated below) and create figures from those data.\n",
    "#  The data in the CSV should be either sweHybrid, swe, or melt.\n",
    "#  Although the display/management of the data for all three types is pretty similar, MELT should be displayed\n",
    "#  slightly differently than sweHybrid or swe.    Special MELT scripts will be written for this management\n",
    "#\n",
    "#\n",
    "#    Each row should be a different pond.    There is no label for the ponds in the CSV the meta data should be\n",
    "#        handled carefully there.\n",
    "#    The first row is the date values\n",
    "#    Each column is a new day   with the first row of each column being the date (in matlab dates cause hecc)\n",
    "#\n",
    "#    date, date, date, date\n",
    "#    value_p1, value_p1, value_p1, value_p1\n",
    "#    value_p2, value_p2, value_p2, value_p2\n",
    "#    value_p3, value_p3, value_p3, value_p3\n",
    "#\n",
    "# Each value should be some combination of total melt across the area of the pond.  Either Sum, average, or \n",
    "#    Otherwise.   This script will have absolutly no vision into how those data are calculated so be smart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64eb484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68d754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was copied from https://gist.github.com/victorkristof/b9d794fe1ed12e708b9d\n",
    "# seemed legit but I havent actually checked their work.   I think it should do the trick tho\n",
    "def datenum_to_datetime(datenum):\n",
    "    \"\"\"\n",
    "    Convert Matlab datenum into Python datetime.\n",
    "    :param datenum: Date in datenum format\n",
    "    :return:        Datetime object corresponding to datenum.\n",
    "    \"\"\"\n",
    "    days = datenum % 1\n",
    "    return datetime.date.fromordinal(int(datenum)) \\\n",
    "           + datetime.timedelta(days=days) \\\n",
    "           - datetime.timedelta(days=366)\n",
    "\n",
    "#The name of this function is intentionally obscure to limit it's use.   It is not very universal\n",
    "# But it works for my initial 26 ponds assuming they are in a consistant order.   This is not garunteed for\n",
    "# all ponds though so this method should be used VERY sparingly.   Mostly just creates my initial dataframes\n",
    "# Gets the raw data from the CSV file and organizes it into a pandas df for later\n",
    "#\n",
    "def custom_function_that_is_specific_to_data_type(pond_df, raw_data_csv_file, raw_data_df, data_key):\n",
    "    print('this function takes a while.... Sorry it has for loops')\n",
    "    raw_pond_file = open(raw_data_csv_file)\n",
    "    raw_pond_data_reader = csv.reader(raw_pond_file)\n",
    "    for idx, row in enumerate(raw_pond_data_reader):\n",
    "        if idx == 0:\n",
    "            dates = list(map(datenum_to_datetime, \n",
    "                             list(map(float, row)))) #creates datetime list in python format\n",
    "            continue\n",
    "        site_data = list(map(float, row))\n",
    "        site_id = pond_df['site_id'].iloc[idx-1]\n",
    "        for date, site_value in zip(dates, site_data):\n",
    "            temporary_dict = {\"site_id\": site_id, \"date\": date, data_key: site_value, \n",
    "                             \"units\": 'mm', \"area_size_m\": 500, \n",
    "                              \"averaging_method\": 'sum'}\n",
    "            raw_data_df = raw_data_df.append(temporary_dict, ignore_index=True)\n",
    "    return(raw_data_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91eb0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The meta data should ultimatly be included in the raw data file instead of two separate files...\n",
    "# These should be changed each time too.\n",
    "swe_hybrid_raw_data_csv_file = \"/Users/Cannon/Documents/School/UCSB/Briggs Lab/Thaw_Rate_Hypothesis/Raw Snow Melt Data (Bair et. Al) /Points_OF_Interest/Pond_csv_data/18-Dec-2023sweHybrid_2007_2018.csv\"\n",
    "melt_raw_data_csv = \"/Users/Cannon/Documents/School/UCSB/Briggs Lab/Thaw_Rate_Hypothesis/Raw Snow Melt Data (Bair et. Al) /Points_OF_Interest/Pond_csv_data/05-Dec-2023melt_2001_2006.csv\"\n",
    "swe_raw_data_csv = \"/Users/Cannon/Documents/School/UCSB/Briggs Lab/Thaw_Rate_Hypothesis/Raw Snow Melt Data (Bair et. Al) /Points_OF_Interest/Pond_csv_data/05-Dec-2023swe_2001_2006.csv\"\n",
    "pond_meta_data_csv = \"/Users/Cannon/Documents/School/UCSB/Briggs Lab/Thaw_Rate_Hypothesis/Raw Snow Melt Data (Bair et. Al) /Points_OF_Interest/Initial_Ponds.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a4c4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eventually these will be the same cause we just want to update the old one.\n",
    "# But we are being very careful with this because we don't wanna overwrite out data\n",
    "#\n",
    "# Will need to change these each time to the most recent exsiting DF and the new name for the next df\n",
    "\n",
    "# Where we will save the df\n",
    "save_all_data_csv = \"/Users/Cannon/Documents/School/UCSB/Briggs Lab/Thaw_Rate_Hypothesis/Raw Snow Melt Data (Bair et. Al) /Points_OF_Interest/DataFrame_CSV/dec_19_all_melt.csv\" # Where we will save the df\n",
    "\n",
    "existing_df = \"/Users/Cannon/Documents/School/UCSB/Briggs Lab/Thaw_Rate_Hypothesis/Raw Snow Melt Data (Bair et. Al) /Points_OF_Interest/DataFrame_CSV/dec_6_all_melt.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a17c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gest meta data from meta data file and creates the master data frame\n",
    "meta_pond_file = open(pond_meta_data_csv)\n",
    "meta_pond_data_reader = csv.reader(meta_pond_file)\n",
    "meta_pond_data = []\n",
    "keys = []\n",
    "for idx, row in enumerate(meta_pond_data_reader):\n",
    "    if idx == 0:\n",
    "        keys = list(row)\n",
    "        continue\n",
    "    meta_pond_data.append(list(row))\n",
    "pond_df = pd.DataFrame(meta_pond_data, columns = keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167de73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b660f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this function takes a while.... Sorry it has for loops\n",
      "this function takes a while.... Sorry it has for loops\n",
      "this function takes a while.... Sorry it has for loops\n"
     ]
    }
   ],
   "source": [
    "melt_type_columns = [\"site_id\", \"date\", \"value\", \"units\", \"area_size_m\", \"averaging_method\"]\n",
    "sweHybrid_df = pd.DataFrame(columns = melt_type_columns)\n",
    "swe_df = pd.DataFrame(columns = melt_type_columns)\n",
    "melt_df = pd.DataFrame(columns = melt_type_columns)\n",
    "\n",
    "sweHybrid_df = custom_function_that_is_specific_to_data_type(pond_df, \n",
    "                                                             swe_hybrid_raw_data_csv_file, \n",
    "                                                             sweHybrid_df,\n",
    "                                                             'sweHybrid')\n",
    "melt_df = custom_function_that_is_specific_to_data_type(pond_df, \n",
    "                                                             melt_raw_data_csv, \n",
    "                                                             melt_df,\n",
    "                                                             'melt')\n",
    "swe_df = custom_function_that_is_specific_to_data_type(pond_df, \n",
    "                                                             swe_raw_data_csv, \n",
    "                                                             swe_df,\n",
    "                                                             'swe')\n",
    "\n",
    "all_data = pd.merge(sweHybrid_df, melt_df, on=[\"site_id\", \"date\"], suffixes=('', '_df2'))\n",
    "columns_to_delete = ['value_df2', 'units_df2', 'area_size_m_df2', 'averaging_method_df2']\n",
    "all_data = all_data.drop(columns=columns_to_delete)\n",
    "\n",
    "all_data = pd.merge(all_data, swe_df, on=[\"site_id\", \"date\"], suffixes=('', '_df2'))\n",
    "columns_to_delete = ['value_df2', 'units_df2', 'area_size_m_df2', 'averaging_method_df2']\n",
    "all_data = all_data.drop(columns=columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8313fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>units</th>\n",
       "      <th>area_size_m</th>\n",
       "      <th>averaging_method</th>\n",
       "      <th>sweHybrid</th>\n",
       "      <th>melt</th>\n",
       "      <th>swe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10206</td>\n",
       "      <td>2006-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10206</td>\n",
       "      <td>2006-10-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10206</td>\n",
       "      <td>2006-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10206</td>\n",
       "      <td>2006-10-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10206</td>\n",
       "      <td>2006-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109195</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109196</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109197</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109198</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109199</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       site_id        date  value units area_size_m averaging_method  \\\n",
       "0        10206  2006-10-01    NaN    mm         500              sum   \n",
       "1        10206  2006-10-02    NaN    mm         500              sum   \n",
       "2        10206  2006-10-03    NaN    mm         500              sum   \n",
       "3        10206  2006-10-04    NaN    mm         500              sum   \n",
       "4        10206  2006-10-05    NaN    mm         500              sum   \n",
       "...        ...         ...    ...   ...         ...              ...   \n",
       "109195   72996  2018-09-11    NaN    mm         500              sum   \n",
       "109196   72996  2018-09-12    NaN    mm         500              sum   \n",
       "109197   72996  2018-09-13    NaN    mm         500              sum   \n",
       "109198   72996  2018-09-14    NaN    mm         500              sum   \n",
       "109199   72996  2018-09-15    NaN    mm         500              sum   \n",
       "\n",
       "        sweHybrid  melt  swe  \n",
       "0             0.0     0    0  \n",
       "1             0.0     0    0  \n",
       "2             0.0     0    0  \n",
       "3             0.0     0    0  \n",
       "4             0.0     0    0  \n",
       "...           ...   ...  ...  \n",
       "109195        0.0     0    0  \n",
       "109196        0.0     0    0  \n",
       "109197        0.0     0    0  \n",
       "109198        0.0     0    0  \n",
       "109199        0.0     0    0  \n",
       "\n",
       "[109200 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block is usually commented out.   If you don't have melt, swe, and swehybrid then merging them doesnt\n",
    "# work.   So you have to create the columns of melt and swe and just set them to some nan value (or 0)\n",
    "# ====== Code below ===== #\n",
    "\n",
    "# sweHybrid_df['melt'] = 0\n",
    "# sweHybrid_df['swe'] = 0\n",
    "# all_data = sweHybrid_df\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0f63623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site_Data: 191100\n",
      "Dropped_Dubplicates: 191100\n",
      "-----------\n",
      "The site_data and Dropped_Duplicates should be same length\n",
      "diff = 0\n"
     ]
    }
   ],
   "source": [
    "# At this point we should have all the data from the new DFs so all we gotta do now is merge that with \n",
    "# The existing dataframe.)\n",
    "site_data = pd.read_csv(existing_df)\n",
    "site_data = site_data.append(all_data, ignore_index = True) #Should append the two dataframes\n",
    "#This section will check the df for repeats\n",
    "#duplicates = site_data[site_data.duplicated(subset=['site_id', 'date'], keep=False)]\n",
    "drop_dup = site_data.drop_duplicates() #only checks for duplicates\n",
    "print(f\"Site_Data: {len(site_data)}\")\n",
    "print(f\"Dropped_Dubplicates: {len(drop_dup)}\")\n",
    "print(\"-----------\")\n",
    "print(\"The site_data and Dropped_Duplicates should be same length\")\n",
    "print(f\"diff = {len(site_data) - len(drop_dup)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "080627fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>units</th>\n",
       "      <th>area_size_m</th>\n",
       "      <th>averaging_method</th>\n",
       "      <th>sweHybrid</th>\n",
       "      <th>melt</th>\n",
       "      <th>swe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10206.0</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10206.0</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10206.0</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10206.0</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10206.0</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191095</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191096</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191097</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191098</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191099</th>\n",
       "      <td>72996</td>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>500</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        site_id        date  value units area_size_m averaging_method  \\\n",
       "0       10206.0  2018-10-01    NaN    mm         500              sum   \n",
       "1       10206.0  2018-10-02    NaN    mm         500              sum   \n",
       "2       10206.0  2018-10-03    NaN    mm         500              sum   \n",
       "3       10206.0  2018-10-04    NaN    mm         500              sum   \n",
       "4       10206.0  2018-10-05    NaN    mm         500              sum   \n",
       "...         ...         ...    ...   ...         ...              ...   \n",
       "191095    72996  2018-09-11    NaN    mm         500              sum   \n",
       "191096    72996  2018-09-12    NaN    mm         500              sum   \n",
       "191097    72996  2018-09-13    NaN    mm         500              sum   \n",
       "191098    72996  2018-09-14    NaN    mm         500              sum   \n",
       "191099    72996  2018-09-15    NaN    mm         500              sum   \n",
       "\n",
       "        sweHybrid  melt  swe  \n",
       "0             0.0   0.0  0.0  \n",
       "1             0.0   0.0  0.0  \n",
       "2             0.0   0.0  0.0  \n",
       "3             0.0   0.0  0.0  \n",
       "4             0.0   0.0  0.0  \n",
       "...           ...   ...  ...  \n",
       "191095        0.0   0.0  0.0  \n",
       "191096        0.0   0.0  0.0  \n",
       "191097        0.0   0.0  0.0  \n",
       "191098        0.0   0.0  0.0  \n",
       "191099        0.0   0.0  0.0  \n",
       "\n",
       "[191100 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "904a78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_dup.to_csv(save_all_data_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e80b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
